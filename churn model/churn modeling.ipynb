{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"churn modeling.ipynb","provenance":[],"mount_file_id":"1LwHDuaW6_jAKRc-kTZholD5uCEG-ayZx","authorship_tag":"ABX9TyOTdumqJxS1BXdsQkn5EiJB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y6Ek49xLXJ9j","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602499087771,"user_tz":-330,"elapsed":163341,"user":{"displayName":"Naresh Nari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGrzY3-rJlPRxwA9ZL-D2mqcA1ffWrIwwV8ABhLg=s64","userId":"11991592827044805555"}},"outputId":"70938a1d-2b7a-48f4-9131-26ed9d7ae33a"},"source":["\n","# Part 1 - Data Preprocessing\n","\n","# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Importing the dataset\n","dataset = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ann/ann1.csv\")\n","X = dataset.iloc[:, 3:13]\n","y = dataset.iloc[:, 13]\n","\n","#Create dummy variables\n","geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n","gender=pd.get_dummies(X['Gender'],drop_first=True)\n","\n","## Concatenate the Data Frames\n","\n","X=pd.concat([X,geography,gender],axis=1)\n","\n","## Drop Unnecessary columns\n","X=X.drop(['Geography','Gender'],axis=1)\n","\n","# Splitting the dataset into the Training set and Test set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","\n","# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Part 2 - Now let's make the ANN!\n","\n","# Importing the Keras libraries and packages\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LeakyReLU,PReLU,ELU\n","from keras.layers import Dropout\n","\n","\n","# Initialising the ANN\n","classifier = Sequential()\n","\n","# Adding the input layer and the first hidden layer\n","classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu',input_dim = 11))\n","\n","# Adding the second hidden layer\n","classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))\n","# Adding the output layer\n","classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n","\n","# Compiling the ANN\n","classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","# Fitting the ANN to the Training set\n","model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.6786 - accuracy: 0.6358 - val_loss: 0.5422 - val_accuracy: 0.7565\n","Epoch 2/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.7832 - val_loss: 0.4992 - val_accuracy: 0.7906\n","Epoch 3/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.4897 - accuracy: 0.7953 - val_loss: 0.4862 - val_accuracy: 0.7944\n","Epoch 4/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4789 - accuracy: 0.7975 - val_loss: 0.4780 - val_accuracy: 0.7955\n","Epoch 5/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4703 - accuracy: 0.7979 - val_loss: 0.4709 - val_accuracy: 0.7989\n","Epoch 6/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4626 - accuracy: 0.8003 - val_loss: 0.4644 - val_accuracy: 0.7989\n","Epoch 7/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8029 - val_loss: 0.4589 - val_accuracy: 0.8001\n","Epoch 8/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8057 - val_loss: 0.4536 - val_accuracy: 0.8005\n","Epoch 9/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4437 - accuracy: 0.8093 - val_loss: 0.4486 - val_accuracy: 0.8020\n","Epoch 10/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4382 - accuracy: 0.8123 - val_loss: 0.4438 - val_accuracy: 0.8058\n","Epoch 11/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4332 - accuracy: 0.8141 - val_loss: 0.4392 - val_accuracy: 0.8073\n","Epoch 12/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.8153 - val_loss: 0.4353 - val_accuracy: 0.8092\n","Epoch 13/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4239 - accuracy: 0.8186 - val_loss: 0.4317 - val_accuracy: 0.8099\n","Epoch 14/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.4200 - accuracy: 0.8199 - val_loss: 0.4286 - val_accuracy: 0.8107\n","Epoch 15/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4167 - accuracy: 0.8225 - val_loss: 0.4259 - val_accuracy: 0.8141\n","Epoch 16/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4139 - accuracy: 0.8233 - val_loss: 0.4236 - val_accuracy: 0.8160\n","Epoch 17/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4113 - accuracy: 0.8233 - val_loss: 0.4216 - val_accuracy: 0.8175\n","Epoch 18/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.4089 - accuracy: 0.8259 - val_loss: 0.4194 - val_accuracy: 0.8183\n","Epoch 19/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4065 - accuracy: 0.8259 - val_loss: 0.4178 - val_accuracy: 0.8179\n","Epoch 20/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4040 - accuracy: 0.8257 - val_loss: 0.4160 - val_accuracy: 0.8194\n","Epoch 21/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.4021 - accuracy: 0.8270 - val_loss: 0.4139 - val_accuracy: 0.8201\n","Epoch 22/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3997 - accuracy: 0.8268 - val_loss: 0.4120 - val_accuracy: 0.8201\n","Epoch 23/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8289 - val_loss: 0.4102 - val_accuracy: 0.8198\n","Epoch 24/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3946 - accuracy: 0.8306 - val_loss: 0.4081 - val_accuracy: 0.8239\n","Epoch 25/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3916 - accuracy: 0.8324 - val_loss: 0.4056 - val_accuracy: 0.8232\n","Epoch 26/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3880 - accuracy: 0.8343 - val_loss: 0.4027 - val_accuracy: 0.8254\n","Epoch 27/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3842 - accuracy: 0.8382 - val_loss: 0.3995 - val_accuracy: 0.8289\n","Epoch 28/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3797 - accuracy: 0.8421 - val_loss: 0.3959 - val_accuracy: 0.8304\n","Epoch 29/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8472 - val_loss: 0.3927 - val_accuracy: 0.8349\n","Epoch 30/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3712 - accuracy: 0.8492 - val_loss: 0.3899 - val_accuracy: 0.8383\n","Epoch 31/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3674 - accuracy: 0.8535 - val_loss: 0.3870 - val_accuracy: 0.8398\n","Epoch 32/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3639 - accuracy: 0.8545 - val_loss: 0.3844 - val_accuracy: 0.8417\n","Epoch 33/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8556 - val_loss: 0.3823 - val_accuracy: 0.8444\n","Epoch 34/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3582 - accuracy: 0.8569 - val_loss: 0.3805 - val_accuracy: 0.8440\n","Epoch 35/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3560 - accuracy: 0.8584 - val_loss: 0.3788 - val_accuracy: 0.8451\n","Epoch 36/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3542 - accuracy: 0.8597 - val_loss: 0.3777 - val_accuracy: 0.8459\n","Epoch 37/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3526 - accuracy: 0.8593 - val_loss: 0.3765 - val_accuracy: 0.8466\n","Epoch 38/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3510 - accuracy: 0.8599 - val_loss: 0.3757 - val_accuracy: 0.8466\n","Epoch 39/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8599 - val_loss: 0.3746 - val_accuracy: 0.8474\n","Epoch 40/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3486 - accuracy: 0.8606 - val_loss: 0.3740 - val_accuracy: 0.8470\n","Epoch 41/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3476 - accuracy: 0.8600 - val_loss: 0.3730 - val_accuracy: 0.8474\n","Epoch 42/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8608 - val_loss: 0.3723 - val_accuracy: 0.8466\n","Epoch 43/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3456 - accuracy: 0.8602 - val_loss: 0.3717 - val_accuracy: 0.8482\n","Epoch 44/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3448 - accuracy: 0.8600 - val_loss: 0.3709 - val_accuracy: 0.8501\n","Epoch 45/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3441 - accuracy: 0.8597 - val_loss: 0.3705 - val_accuracy: 0.8493\n","Epoch 46/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3434 - accuracy: 0.8606 - val_loss: 0.3699 - val_accuracy: 0.8493\n","Epoch 47/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3429 - accuracy: 0.8610 - val_loss: 0.3695 - val_accuracy: 0.8508\n","Epoch 48/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8606 - val_loss: 0.3689 - val_accuracy: 0.8493\n","Epoch 49/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3418 - accuracy: 0.8602 - val_loss: 0.3684 - val_accuracy: 0.8516\n","Epoch 50/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8604 - val_loss: 0.3681 - val_accuracy: 0.8512\n","Epoch 51/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3408 - accuracy: 0.8602 - val_loss: 0.3675 - val_accuracy: 0.8501\n","Epoch 52/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3403 - accuracy: 0.8619 - val_loss: 0.3671 - val_accuracy: 0.8493\n","Epoch 53/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8606 - val_loss: 0.3669 - val_accuracy: 0.8493\n","Epoch 54/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3396 - accuracy: 0.8608 - val_loss: 0.3663 - val_accuracy: 0.8504\n","Epoch 55/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3392 - accuracy: 0.8604 - val_loss: 0.3660 - val_accuracy: 0.8493\n","Epoch 56/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8612 - val_loss: 0.3656 - val_accuracy: 0.8493\n","Epoch 57/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3384 - accuracy: 0.8604 - val_loss: 0.3654 - val_accuracy: 0.8501\n","Epoch 58/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8610 - val_loss: 0.3653 - val_accuracy: 0.8497\n","Epoch 59/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3379 - accuracy: 0.8606 - val_loss: 0.3649 - val_accuracy: 0.8493\n","Epoch 60/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3374 - accuracy: 0.8599 - val_loss: 0.3646 - val_accuracy: 0.8512\n","Epoch 61/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3373 - accuracy: 0.8606 - val_loss: 0.3644 - val_accuracy: 0.8501\n","Epoch 62/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3370 - accuracy: 0.8617 - val_loss: 0.3642 - val_accuracy: 0.8497\n","Epoch 63/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3368 - accuracy: 0.8593 - val_loss: 0.3640 - val_accuracy: 0.8504\n","Epoch 64/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3366 - accuracy: 0.8612 - val_loss: 0.3636 - val_accuracy: 0.8501\n","Epoch 65/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8619 - val_loss: 0.3635 - val_accuracy: 0.8493\n","Epoch 66/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8615 - val_loss: 0.3636 - val_accuracy: 0.8504\n","Epoch 67/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3360 - accuracy: 0.8621 - val_loss: 0.3631 - val_accuracy: 0.8501\n","Epoch 68/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3358 - accuracy: 0.8612 - val_loss: 0.3629 - val_accuracy: 0.8508\n","Epoch 69/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3357 - accuracy: 0.8615 - val_loss: 0.3629 - val_accuracy: 0.8497\n","Epoch 70/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3354 - accuracy: 0.8615 - val_loss: 0.3626 - val_accuracy: 0.8504\n","Epoch 71/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3352 - accuracy: 0.8614 - val_loss: 0.3622 - val_accuracy: 0.8504\n","Epoch 72/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3351 - accuracy: 0.8625 - val_loss: 0.3621 - val_accuracy: 0.8504\n","Epoch 73/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8617 - val_loss: 0.3624 - val_accuracy: 0.8497\n","Epoch 74/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3347 - accuracy: 0.8632 - val_loss: 0.3623 - val_accuracy: 0.8501\n","Epoch 75/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.8614 - val_loss: 0.3622 - val_accuracy: 0.8504\n","Epoch 76/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3345 - accuracy: 0.8628 - val_loss: 0.3621 - val_accuracy: 0.8497\n","Epoch 77/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8621 - val_loss: 0.3621 - val_accuracy: 0.8508\n","Epoch 78/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8643 - val_loss: 0.3616 - val_accuracy: 0.8485\n","Epoch 79/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8632 - val_loss: 0.3615 - val_accuracy: 0.8482\n","Epoch 80/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3338 - accuracy: 0.8636 - val_loss: 0.3613 - val_accuracy: 0.8482\n","Epoch 81/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3338 - accuracy: 0.8627 - val_loss: 0.3612 - val_accuracy: 0.8489\n","Epoch 82/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3334 - accuracy: 0.8630 - val_loss: 0.3611 - val_accuracy: 0.8493\n","Epoch 83/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3335 - accuracy: 0.8634 - val_loss: 0.3611 - val_accuracy: 0.8501\n","Epoch 84/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8632 - val_loss: 0.3609 - val_accuracy: 0.8493\n","Epoch 85/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8634 - val_loss: 0.3607 - val_accuracy: 0.8501\n","Epoch 86/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3330 - accuracy: 0.8632 - val_loss: 0.3606 - val_accuracy: 0.8493\n","Epoch 87/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8627 - val_loss: 0.3608 - val_accuracy: 0.8478\n","Epoch 88/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8625 - val_loss: 0.3610 - val_accuracy: 0.8478\n","Epoch 89/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8634 - val_loss: 0.3605 - val_accuracy: 0.8482\n","Epoch 90/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8623 - val_loss: 0.3605 - val_accuracy: 0.8478\n","Epoch 91/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3323 - accuracy: 0.8623 - val_loss: 0.3605 - val_accuracy: 0.8474\n","Epoch 92/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3324 - accuracy: 0.8623 - val_loss: 0.3606 - val_accuracy: 0.8497\n","Epoch 93/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8628 - val_loss: 0.3601 - val_accuracy: 0.8489\n","Epoch 94/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3321 - accuracy: 0.8623 - val_loss: 0.3605 - val_accuracy: 0.8493\n","Epoch 95/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8621 - val_loss: 0.3605 - val_accuracy: 0.8470\n","Epoch 96/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8640 - val_loss: 0.3604 - val_accuracy: 0.8493\n","Epoch 97/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8634 - val_loss: 0.3606 - val_accuracy: 0.8482\n","Epoch 98/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3316 - accuracy: 0.8621 - val_loss: 0.3606 - val_accuracy: 0.8497\n","Epoch 99/100\n","536/536 [==============================] - 2s 3ms/step - loss: 0.3316 - accuracy: 0.8640 - val_loss: 0.3603 - val_accuracy: 0.8470\n","Epoch 100/100\n","536/536 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8630 - val_loss: 0.3604 - val_accuracy: 0.8474\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SS8fCoX-YQ85"},"source":["# Part 3 - Making the predictions and evaluating the model\n","\n","# Predicting the Test set results\n","y_pred = classifier.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","\n","# Making the Confusion Matrix\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Calculate the Accuracy\n","from sklearn.metrics import accuracy_score\n","score=accuracy_score(y_pred,y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4FUuRncAZWXB","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602499226240,"user_tz":-330,"elapsed":1435,"user":{"displayName":"Naresh Nari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGrzY3-rJlPRxwA9ZL-D2mqcA1ffWrIwwV8ABhLg=s64","userId":"11991592827044805555"}},"outputId":"29d16898-bde6-4a9e-cb21-0fb2c3d21a7d"},"source":["score"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8585"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"V--oq7FuZZ9B","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1602499233618,"user_tz":-330,"elapsed":1341,"user":{"displayName":"Naresh Nari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgGrzY3-rJlPRxwA9ZL-D2mqcA1ffWrIwwV8ABhLg=s64","userId":"11991592827044805555"}},"outputId":"3f097905-2726-46f1-c17e-ab4389941a76"},"source":["cm"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1518,   77],\n","       [ 206,  199]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"je7mgOQNZcCI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3hYGcz_ZLaH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnSU97scYBBV"},"source":[""],"execution_count":null,"outputs":[]}]}
